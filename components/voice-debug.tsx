'use client';

import { useState, useEffect } from 'react';
import { Button } from '@/components/ui/button';
import { Card } from '@/components/ui/card';

export function VoiceDebug() {
  const [diagnostics, setDiagnostics] = useState<string[]>([]);
  const [apiKeyStatus, setApiKeyStatus] = useState<string>('checking...');
  const [microphoneStatus, setMicrophoneStatus] = useState<string>('checking...');
  const [speechRecognitionStatus, setSpeechRecognitionStatus] = useState<string>('checking...');

  const addDiagnostic = (message: string) => {
    setDiagnostics(prev => [...prev, `${new Date().toLocaleTimeString()}: ${message}`]);
  };

  const runDiagnostics = async () => {
    setDiagnostics([]);
    addDiagnostic('Starting voice system diagnostics...');

    // Check Speech Recognition API
    const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
    if (SpeechRecognition) {
      setSpeechRecognitionStatus('âœ… Available');
      addDiagnostic('âœ… Speech Recognition API is available');
    } else {
      setSpeechRecognitionStatus('âŒ Not supported');
      addDiagnostic('âŒ Speech Recognition API is not supported in this browser');
    }

    // Check API key
    try {
      const response = await fetch('/api/config');
      if (response.ok) {
        const data = await response.json();
        if (data.openaiKey && data.openaiKey !== 'your-openai-api-key-here') {
          setApiKeyStatus('âœ… Valid');
          addDiagnostic('âœ… OpenAI API key is configured');
        } else {
          setApiKeyStatus('âŒ Not configured');
          addDiagnostic('âŒ OpenAI API key is not configured');
        }
      } else {
        setApiKeyStatus('âŒ Error checking');
        addDiagnostic('âŒ Error checking API key status');
      }
    } catch (error) {
      setApiKeyStatus('âŒ Error');
      addDiagnostic(`âŒ Error checking API key: ${error}`);
    }

    // Check microphone access
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      setMicrophoneStatus('âœ… Access granted');
      addDiagnostic('âœ… Microphone access granted');
      stream.getTracks().forEach(track => track.stop());
    } catch (error) {
      setMicrophoneStatus('âŒ Access denied');
      addDiagnostic(`âŒ Microphone access denied: ${error}`);
    }

    // Test button click
    addDiagnostic('âœ… Voice button is responsive');
  };

  const testButtonClick = () => {
    addDiagnostic('ğŸ–±ï¸ Voice button clicked successfully');
  };

  useEffect(() => {
    runDiagnostics();
  }, []);

  return (
    <Card className="p-2 max-w-xs text-xs">
      <div className="space-y-1 mb-2">
        <div>ğŸ”‘ {apiKeyStatus}</div>
        <div>ğŸ¤ {microphoneStatus}</div>
        <div>ğŸ—£ï¸ {speechRecognitionStatus}</div>
      </div>

      <Button onClick={runDiagnostics} size="sm" className="text-xs h-6">
        Refresh
      </Button>
    </Card>
  );
}
